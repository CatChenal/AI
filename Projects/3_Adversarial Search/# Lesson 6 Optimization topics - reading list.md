# Lesson 6 Optimization topics - reading list

## General
* [Derivative Free Optimization @CMU](http://thales.cheme.cmu.edu/dfo/comparison/dfo.pdf)
 
* [Gradient Free Optimization @Standford](http://adl.stanford.edu/aa222/lecture_notes_files/chapter6_gradfree.pdf)

For another viewpoint and some extensions, check out Charles Isbell and Michael Littman’s Machine Learning course section on this topic: 
* [Randomized Optimization @Udacity_ud741](https://classroom.udacity.com/courses/ud741/lessons/521298714/concepts/5344086080923)
* [Late Acceptance Hill Climbing @ScienceDirect](https://www.sciencedirect.com/science/article/abs/pii/S0377221716305495)
 ** [Applied to Shipping Fleet @paper by K. Tierney](https://wiwi.uni-paderborn.de/fileadmin/dep3ls7/Downloads/Publikationen/PDFs/lahc-lsfrp-eume2013.pdf)
><b>Abstract</b>
Late Acceptance Hill Climbing (LAHC) has been shown to be an effective local search method for several types of optimization problems, such as on certain types of scheduling problems as well as the traveling
salesman problem. We apply LAHC to a central problem in the liner shipping industry, the Liner Shipping
Fleet Repositioning Problem (LSFRP). The LSFRP involves the movement of vessels between routes in a liner
shipping network subject to complex costs and timing restrictions. We show that despite LAHC’s promising
performance on other problems, it is unable to achieve the performance of simulated annealing on the LSFRP.  

* [Basin hopping](https://arxiv.org/pdf/cond-mat/0402136.pdf)

* [Neuroevolution (Genetic algorithms) @arxiv](https://arxiv.org/pdf/1703.00548.pdf)
* [NEAT: NeuroEvolution of Augmenting Topologies @UTexas](http://nn.cs.utexas.edu/?neat)

## Gradient-Free Optimization Algorithms
* [Tabu search @wikipedia](https://en.wikipedia.org/wiki/Tabu_search)
* [Differential evolution @wikipedia](https://en.wikipedia.org/wiki/Differential_evolution)
* [Particle swarm optimization @wikipedia](https://en.wikipedia.org/wiki/Particle_swarm_optimization)
* [Evolutionary strategies @arxiv](https://arxiv.org/pdf/1703.03864.pdf)

## Gradient-Based Optimization Algorithms
* [Gradient Descent @wikipedia](https://en.wikipedia.org/wiki/Gradient_descent)
* [Quasi-Newtonian methods @wikipedia](https://en.wikipedia.org/wiki/Quasi-Newton_method)
* [Levenburg-Marquardt @wikipedia](https://en.wikipedia.org/wiki/Levenberg%E2%80%93Marquardt_algorithm)
